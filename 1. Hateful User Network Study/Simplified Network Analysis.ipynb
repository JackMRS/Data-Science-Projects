{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Yueshuwei Wu\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import community\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 100386\n",
      "Number of edges: 2286592\n",
      "Average in degree:  22.7780\n",
      "Average out degree:  22.7780\n"
     ]
    }
   ],
   "source": [
    "# Read the original edge list \n",
    "G = nx.read_edgelist('users edge list.txt',comments='#', delimiter=None, create_using=nx.DiGraph, nodetype=None, encoding='utf-8')\n",
    "print (nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information for nodes\n",
    "data_s=[]\n",
    "with open(\"ver. 4 users_neighborhood_anon.csv\",\"r\") as file:\n",
    "    for line in file:\n",
    "        data = line.strip().split(\",\")\n",
    "        data_s.append(data)\n",
    "tag =data_s[0]\n",
    "\n",
    "users=[]\n",
    "for data in data_s[1:]:\n",
    "    user=dict(zip(tag,data))\n",
    "    users.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'hate', 'statuses_count', 'followers_count', 'followees_count', 'favorites_count', 'listed_count', 'sentiment', 'subjectivity', 'number hashtags', 'tweet number', 'retweet number', 'quote number', 'status length', 'number urls', 'baddies', 'mentions']\n",
      "['1', 'other', '2352', '19609', '309', '61', '197', '0.088142078', '0.418649474', '40', '199', '0', '0', '101.7135678', '20', '10', '6']\n",
      "['4', 'other', '1998', '17643', '19355', '485', '239', '0.121533267', '0.435334321', '1710', '101', '99', '0', '152.175', '198', '35', '7']\n"
     ]
    }
   ],
   "source": [
    "print(data_s[0])\n",
    "print(data_s[2])\n",
    "print(data_s[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Community Id List.XLSX') # can also index sheet by name or fetch all sheets\n",
    "conservatives = df['Conservative'].tolist()\n",
    "c_users=[]\n",
    "for user in users:\n",
    "    if float(user['user_id']) in conservatives:\n",
    "        c_users.append(user)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_nodes=[]\n",
    "c_edges=[]\n",
    "\n",
    "for user in c_users:\n",
    "    c_nodes.append(user['user_id'])\n",
    "\n",
    "\n",
    "edges=[]\n",
    "with open(\"users edge list.txt\",\"r\") as file:\n",
    "    for line in file:\n",
    "        edge = line.strip().split(\" \")\n",
    "        edges.append(edge)\n",
    "\n",
    "# we only need the retweet network of our target users,which is the edge coming in\n",
    "# also get filter out the self-loops\n",
    "for edge in edges:\n",
    "    if ((edge[1] in c_nodes))and (edge[0]!=edge[1]):\n",
    "        c_edges.append(edge)\n",
    "\n",
    "#Save the edge list for future use\n",
    "with open(\"C Edges.csv\",\"w\") as file:\n",
    "    for e in c_edges:\n",
    "        file.write(e[0]+','+e[1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the node list for C network\n",
    "with open(\"C Nodes.csv\",\"w\") as file:\n",
    "    file.write('user_id,hate,statuses_count,followers_count,followees_count,favorites_count,listed_count,sentiment,subjectivity,number hashtags,tweet number,retweet number,quote number,status length,number urls,baddies,mentions\\n')\n",
    "    for user in users:\n",
    "        for e in c_edges:\n",
    "            if (user['user_id']in e):\n",
    "                file.write(user['user_id']+','+user['hate']+','+user['statuses_count']+','+user['followers_count']+','+user['followees_count']+','+user['favorites_count']+','+user['listed_count']+','+user['sentiment']+','+user['subjectivity']+','+user['number hashtags']+','+user['tweet number']+','+user['retweet number']+','+user['quote number']+','+user['status length']+','+user['number urls']+','+user['baddies']+','+user['mentions']+'\\n')\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n",
      "4427\n",
      "95413\n"
     ]
    }
   ],
   "source": [
    "#Divide the users into differnt groups\n",
    "h_users=[]\n",
    "n_users=[]\n",
    "o_users=[]\n",
    "\n",
    "for user in users:\n",
    "    if user['hate']=='hateful':\n",
    "            h_users.append(user)\n",
    "    if user['hate']=='normal':\n",
    "            n_users.append(user)\n",
    "    if user['hate']=='other':\n",
    "            o_users.append(user)\n",
    "\n",
    "print(len(h_users))\n",
    "print(len(n_users))\n",
    "print(len(o_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the list and edge file for our target users\n",
    "hn_nodes=[]\n",
    "hn_edges=[]\n",
    "\n",
    "for user in h_users:\n",
    "    hn_nodes.append(user['user_id'])\n",
    "for user in n_users:\n",
    "    hn_nodes.append(user['user_id'])\n",
    "    \n",
    "    \n",
    "edges=[]\n",
    "with open(\"users edge list.txt\",\"r\") as file:\n",
    "    for line in file:\n",
    "        edge = line.strip().split(\" \")\n",
    "        edges.append(edge)\n",
    "\n",
    "# we only need the retweet network of our target users,which is the edge coming in\n",
    "# also get filter out the self-loops\n",
    "for edge in edges:\n",
    "    if ((edge[1] in hn_nodes))and (edge[0]!=edge[1]):\n",
    "        hn_edges.append(edge)\n",
    "\n",
    "#Save the edge list for future use\n",
    "with open(\"HN Edges.csv\",\"w\") as file:\n",
    "    for e in hn_edges:\n",
    "        file.write(e[0]+','+e[1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the node list for HN network\n",
    "with open(\"HN Nodes.csv\",\"w\") as file:\n",
    "    file.write('user_id,hate,statuses_count,followers_count,followees_count,favorites_count,listed_count,sentiment,subjectivity,number hashtags,tweet number,retweet number,quote number,status length,number urls,baddies,mentions\\n')\n",
    "    for user in users:\n",
    "        for e in hn_edges:\n",
    "            if (user['user_id']in e):\n",
    "                file.write(user['user_id']+','+user['hate']+','+user['statuses_count']+','+user['followers_count']+','+user['followees_count']+','+user['favorites_count']+','+user['listed_count']+','+user['sentiment']+','+user['subjectivity']+','+user['number hashtags']+','+user['tweet number']+','+user['retweet number']+','+user['quote number']+','+user['status length']+','+user['number urls']+','+user['baddies']+','+user['mentions']+'\\n')\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the list and edge file for hateful users\n",
    "h_nodes=[]\n",
    "h_edges=[]\n",
    "\n",
    "for user in h_users:\n",
    "    h_nodes.append(user['user_id'])\n",
    "\n",
    "# we only need the retweet network of our target users,which is the edge coming in\n",
    "# also get filter out the self-loops\n",
    "for edge in edges:\n",
    "    if ((edge[1] in h_nodes))and (edge[0]!=edge[1]):\n",
    "        h_edges.append(edge)\n",
    "\n",
    "#Save the edge list for future use\n",
    "with open(\"Hateful Edges.csv\",\"w\") as file:\n",
    "    for e in h_edges:\n",
    "        file.write(e[0]+','+e[1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the node list for H network\n",
    "with open(\"H Nodes.csv\",\"w\") as file:\n",
    "    file.write('user_id,hate,statuses_count,followers_count,followees_count,favorites_count,listed_count,sentiment,subjectivity,number hashtags,tweet number,retweet number,quote number,status length,number urls,baddies,mentions\\n')\n",
    "    for user in users:\n",
    "        for e in h_edges:\n",
    "            if (user['user_id']in e):\n",
    "                file.write(user['user_id']+','+user['hate']+','+user['statuses_count']+','+user['followers_count']+','+user['followees_count']+','+user['favorites_count']+','+user['listed_count']+','+user['sentiment']+','+user['subjectivity']+','+user['number hashtags']+','+user['tweet number']+','+user['retweet number']+','+user['quote number']+','+user['status length']+','+user['number urls']+','+user['baddies']+','+user['mentions']+'\\n')\n",
    "                break\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the list and edge file for normal users\n",
    "n_nodes=[]\n",
    "n_edges=[]\n",
    "\n",
    "for user in n_users:\n",
    "    n_nodes.append(user['user_id'])\n",
    "\n",
    "# we only need the retweet network of our target users,which is the edge coming in\n",
    "# also get filter out the self-loops\n",
    "for edge in edges:\n",
    "    if ((edge[1] in n_nodes))and (edge[0]!=edge[1]):\n",
    "        n_edges.append(edge)\n",
    "\n",
    "#Save the edge list for future use\n",
    "with open(\"Normal Edges.csv\",\"w\") as file:\n",
    "    for e in n_edges:\n",
    "        file.write(e[0]+','+e[1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the node list for N network\n",
    "with open(\"N Nodes.csv\",\"w\") as file:\n",
    "    file.write('user_id,hate,statuses_count,followers_count,followees_count,favorites_count,listed_count,sentiment,subjectivity,number hashtags,tweet number,retweet number,quote number,status length,number urls,baddies,mentions\\n')\n",
    "    for user in users:\n",
    "        for e in n_edges:\n",
    "            if (user['user_id']in e):\n",
    "                file.write(user['user_id']+','+user['hate']+','+user['statuses_count']+','+user['followers_count']+','+user['followees_count']+','+user['favorites_count']+','+user['listed_count']+','+user['sentiment']+','+user['subjectivity']+','+user['number hashtags']+','+user['tweet number']+','+user['retweet number']+','+user['quote number']+','+user['status length']+','+user['number urls']+','+user['baddies']+','+user['mentions']+'\\n')\n",
    "                break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123824\n",
      "16024\n",
      "107800\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Check the number of edges we got\n",
    "print(len(hn_edges))\n",
    "print(len(h_edges))\n",
    "print(len(n_edges))\n",
    "print(len(h_edges)+len(n_edges)-len(hn_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our HN network,\n",
    "Ghn = nx.read_edgelist('HN Edges.txt', comments='#', delimiter=None, create_using=nx.DiGraph, nodetype=None, encoding='utf-8')\n",
    "print (nx.info(Ghn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give the nodes differnt color\n",
    "color_map = []\n",
    "for node in Ghn:\n",
    "    if node in h_nodes:\n",
    "        color_map.append('gold')\n",
    "    elif node in n_nodes:\n",
    "        color_map.append('cornflowerblue')\n",
    "    else:\n",
    "        color_map.append('limegreen')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}